% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/binary-calc-fpr.R
\name{calc_fpr}
\alias{calc_fpr}
\alias{calc_fpr.default}
\alias{calc_fpr.table}
\alias{calc_fpr.data.frame}
\title{Calculate False Positive Rate}
\usage{
calc_fpr(...)

\method{calc_fpr}{default}(fp, tn, ci.type, ci.level, ...)

\method{calc_fpr}{table}(tbl, ci.type, ci.level, ...)

\method{calc_fpr}{data.frame}(data, prediction, reference, ci.type, ci.level, ...)
}
\arguments{
\item{...}{Additional arguments. Not used.}

\item{fp}{Numeric, False Positives (FP).}

\item{tn}{Numeric, True Negatives (TN).}

\item{ci.type}{Either FALSE if no confidence intervals are desired or one of "agresti.coull", "agresti-coull", "ac", "asymptotic", "normal", "wald", "clopper-pearson", "cp", "exact", "jeffreys", "bayes", and "wilson". If FALSE, overwrites ci.level.}

\item{ci.level}{A number between 0 and 1 for the levels of the confidence intervals that
should be calculated.}

\item{tbl}{A table representing the input confusion matrix. This must always have
prediction on rows and reference on columns, otherwise most functions in
rmetrics will generate incorrect results.}

\item{data}{A data.frame containing the prediction and the reference.}

\item{prediction}{Character. The name of the variable in data that contains the predictions.}

\item{reference}{Character. The name of the variable in data that contains the reference
values.}
}
\description{
The false positive rate (FPR) is a measure of the proportion of false
positive results in a binary classification problem. It is calculated as
the number of false positive predictions divided by the total number of
actual negative samples.
}
\details{
To calculate the FPR, the following formula is used:

False positive rate = (Number of false positive predictions) / (Total number of actual negative samples)

The resulting value is a proportion, with values closer to 0 indicating a
better-performing model and values closer to 1 indicating a worse-
performing model.

The FPR is a useful metric to compare the ability of different models
to accurately predict the negative class, and can be used to identify
models that have a high degree of accuracy for the negative class.
}
\section{Methods (by class)}{
\itemize{
\item \code{calc_fpr(default)}: 

\item \code{calc_fpr(table)}: 

\item \code{calc_fpr(data.frame)}: 

}}
