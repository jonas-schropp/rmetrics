% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/binary-calc-fnr.R
\name{calc_fnr}
\alias{calc_fnr}
\alias{calc_fnr.default}
\alias{calc_fnr.table}
\alias{calc_fnr.data.frame}
\title{Calculate False Negative Rate}
\usage{
calc_fnr(...)

\method{calc_fnr}{default}(fn, tp, ci.type, ci.level, ...)

\method{calc_fnr}{table}(tbl, ci.type, ci.level, incr = FALSE, ...)

\method{calc_fnr}{data.frame}(data, prediction, reference, ci.type, ci.level, incr = FALSE, ...)
}
\arguments{
\item{...}{Additional arguments. Not used.}

\item{fn}{Numeric, Fase Negatives (FN).}

\item{tp}{Numeric, True Positives (TP).}

\item{ci.type}{Either FALSE if no confidence intervals are desired or one of
"agresti.coull", "agresti-coull", "ac", "asymptotic", "normal",
"wald", "clopper-pearson", "cp", "exact", "jeffreys", "bayes",
and "wilson". If FALSE, overwrites ci.level.}

\item{ci.level}{A number between 0 and 1 for the levels of the confidence intervals that
should be calculated.}

\item{tbl}{A table representing the input confusion matrix. This must always have
prediction on rows and reference on columns, otherwise most functions in
rmetrics will generate incorrect results.}

\item{incr}{Double. Continuity correction to add to each cell of the table. FALSE
by default, which means the raw counts will be used.}

\item{data}{A data.frame containing the prediction and the reference.}

\item{prediction}{Character. The name of the variable in data that contains the predictions.}

\item{reference}{Character. The name of the variable in data that contains the reference
values.}
}
\description{
The false negative rate is a measure of the proportion of false negative
results in a binary classification problem. It is calculated as the number
of false negative predictions divided by the total number of actual
positive samples.
}
\details{
To calculate the false negative rate, the following formula is used:

False negative rate = (Number of false negative predictions) / (Total number of actual positive samples)

The resulting value is a proportion, with values closer to 0 indicating a
better-performing model and values closer to 1 indicating a worse-
performing model.

Overall, the false negative rate is a useful metric for evaluating
the performance of a classification model. It provides a way to compare
the ability of different models to accurately predict the positive class,
and can be used to identify models that have a high degree of accuracy for
the positive class.
}
\section{Methods (by class)}{
\itemize{
\item \code{calc_fnr(default)}: 

\item \code{calc_fnr(table)}: 

\item \code{calc_fnr(data.frame)}: 

}}
